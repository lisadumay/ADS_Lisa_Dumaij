# ADS Personal portfolio Lisa Dumaij
Naam:               Lisa Dumaij <br />
Studentennummer:    19049838 <br />
Team:               Motoric <br />
<br />
Studie:             Applied Data Science <br />
School:             Haagse Hogeschool <br />
<br />
Datum:              13-01-2022 <br />
Versie:             1 <br />


## 1.Datacamp
<details>
  <summary> Lees hier verder </summary>
  <br />
In deze minor heb ik gebruik gemaakt van het programma DataCamp. Dit was niet de eerste keer dat ik DataCamp heb gebruikt, ik heb dit programma vorig jaar ook gebruikt voor mijn opleiding technische bedrijfskunde. Hierdoor was er soms een overlapping tussen de cursussen die ik moest doen voor deze minor. Omdat ik sommige cursussen al eerder had gedaan kreeg ik de punten er niet voor als ik deze opnieuw deed. Ook waren deze punten niet te zien op de Leaderboard. Wel verder ze als voltooid afgevinkt in de lijst. Deze zijn hieronder in de map foto’s toegevoegd.
  <br />
  <br />
  <details>
  <summary> foto's van cursussen</summary>
<img width="1111" alt="Schermafbeelding 2021-12-18 om 14 41 58" src="https://user-images.githubusercontent.com/91061840/146643266-81b24bfa-6433-47be-98f6-033e42aebe0b.png">
<img width="1116" alt="Schermafbeelding 2021-12-18 om 14 43 49" src="https://user-images.githubusercontent.com/91061840/146643281-e1ae4215-ed82-4144-9f92-695c5c9a5293.png">
<img width="1113" alt="Schermafbeelding 2021-12-18 om 14 44 13" src="https://user-images.githubusercontent.com/91061840/146643284-62f24e7b-ae9a-468e-9858-cb126609fd19.png">

  </details> 
  <br /> 
  <details>
    <br />
  <summary>Samenvatting ervaringen per cursus</summary>
  <details>
  <summary>1.1 Introduction to Python</summary>
    Doordat ik deze cursus al eerder had gedaan, was deze voor mij relatief eenvoudig. Het was fijn om deze cursus als opfriscursus te gebruiken. Het was namelijk een half jaar geleden dat ik eenmalig python had gebruikt, hierdoor was het een beetje had weggevaagd.
    </details>
  <details>
  <summary>1.2 Intermediate Python </summary>
    Deze opleiding had ik ook al eerder gedaan. Ik vond het leuk om in het eerste hoofdstuk weer plots te maken. Vorig jaar vond ik het maken van datavisualisaties een van de leukste onderwerpen en in deze cursus kwam dat even terug. Ook dit hoofdstuk ging vrij snel. In het tweede hoofdstuk werd de import van CSV besproken. Deze code heb ik later ook gebruikt voor het project, zie als voorbeeld de link hieronder . De laatste hoofdstukken waren al wat ingewikkelder, loops vond ik vorig jaar ook al ingewikkeld.
  <br />  
    https://github.com/lisadumay/ADS_Lisa_Dumaij/blob/main/notebooks/Pipeline%20Lisa.ipynb
      </details>
  <details>
  <summary>1.3 Python Data Science toolbox </summary>
    Ik vond het eerste deel van de data science-toolbox ingewikkeld, omdat ik het onderwerp niet helemaal begreep, dus ik zocht video's op YouTube op voor aanvullende uitleg. Daarnaast hield ik de slides naast de opdracht. Hierdoor kon ik terugkijken op hoe ze het in de video hadden gedaan. Dit maakte de stof wat overzichtelijker. Ik vond het tweede deel van deze cursus makkelijker, ik begreep de stof redelijk goed en ging er sneller door dan de cursus ervoor. Ik heb echter ook wel eens de slides bij deze cursus erbij gehouden om in de video terug te kijken hoe het ging.
      </details>
  <details>
  <summary>1.4 Statistical Thinking in Python </summary>
    Ik vond deze cursus erg interessant. Ik heb veel statistiek op mijn opleiding, maar had dit nog nooit in Python gedaan. Ik vond deze combinatie erg leuk, waardoor ik het gevoel had dat ik de cursus snel had afgerond. Ik begreep de statistiek erachter waardoor de stappen in python ook voor mij logisch waren.
      </details>
  <details>
  <summary>1.5 Supervised Learning with scikit-learn </summary>
    Van deze cursus heb ik de code gebruikt om je dataset op te splitsen in trein, test, validatieset. Daarnaast heb ik samen met Mustafa en individueel gewerkt aan een Lasso model. Ik gebruikte ook het schalen van de gegevens in het project. Deze cursus was ook nieuw voor mij, alles wat ik in deze cursus had geleerd was nieuw voor mij, het kunnen toepassen in het project in combinatie met de lessen zorgde ervoor dat ik het beter begreep. De toepassingen van deze cursus is terug te vinden in de link hieronder. 
 <br />     https://github.com/lisadumay/ADS_Lisa_Dumaij/blob/main/notebooks/Lasso.ipynb 
    </details>
  <details>
  <summary>1.6 Introduction to Data Visualization with Matplotlib </summary>
    Datavisualisatie was tot nu toe een van mijn sterke punten in python, wat deze cursus voor mij gemakkelijk maakte. Daarnaast had ik deze cursus al gedaan en ging mijn vorige ervaring met Python vooral over het maken van de visualisaties. Na deze cursus was ik bezig met het maken van verschillende visualisaties voor het project. Deze is te vinden in de link hieronder . Ik vond deze cursus interessant voor al het aanpassen van de grafieken qua kleuren en assen.
     <br /> 
 https://github.com/lisadumay/ADS_Lisa_Dumaij/blob/main/notebooks/visualisaties.ipynb
     </details>
  <details>
  <summary>1.7 Linear Classifiers in Python </summary>
    Net als bij statistical thinking vond ik het leuk om de statistiek toe te passen met Python. Doordat ik de theorie erachter begreep lukte het mij beter om de cursus te volgen. Echter bleef af en toe de toepassing met Python een ingewikkelde stap voor mij.
      </details>
  <details>
  <summary>1.8 Model Validation in Python </summary>
    Deze cursus verliep voor mij soepel. Ik begreep de code erachter en waarom ik de stappen moest doen. Echter hield ik wel af en toe de slides erbij als een reminder hoe ik de stappen moest doen. 
      </details>
  <details>
  <summary>1.9 Data Manipulation with pandas </summary>
    Het was een interessante cursus die ik later in het project kon toepassen. Aan het begin verliep de cursus goed en kon ik de soepel doorheen lopen. Echter na de tweede subhoofdstuk werd het moeilijker en ging ik vaker de presentaties terugkijken. 
      </details>
  <details>
  <summary>1.10 Cleaning Data in Python </summary>
    Deze cursus verliep soepel doordat ik deze cursus al eerder had uitgevoerd en toe had gepast in mijn vorige python ervaring. Ook tijdens het huidige project heb ik deze technieken toegepast zoals te zien is in de link hieronder.
    <br />  https://github.com/lisadumay/ADS_Lisa_Dumaij/blob/main/notebooks/Data%20cleaning.ipynb
      </details>
  <details>
  <summary>1.11 Exploratory Data Analysis in Python </summary>
    Deze cursus verliep voor mij soepel. Ik begreep de code erachter en waarom ik de stappen moest doen.
      </details>
  <details>
  <summary>1.12 Manipulating Time Series Data in Python </summary>
    Deze cursus was minder relevant voor mij omdat mijn project: ‘Motoric’ niet over time series gaat. Echter heb ik wel vaak te maken gehad met time series in mijn studie. 
      </details>
  <details>
  <summary>1.13 Machine Learning for Time Series Data in Python </summary>
    Deze cursus verliep voor mij soepel. Ik begreep de code erachter en waarom ik de stappen moest doen. Echter hield ik wel af en toe de slides erbij als een reminder hoe ik de stappen moest doen. 
     </details>
 <details>
  <summary>1.14 Time Series Analysis in Python </summary>
    Deze cursus was minder relevant voor mij omdat mijn project: ‘Motoric’ niet over time series gaat. Echter heb ik wel vaak te maken gehad met time series in mijn studie. Echter dan minder in python maar vooral de statistieke kant ervan. Het was interessant om te leren hoe dit ook toegepast kan worden in Python.
     </details>
<details>
  <summary>1.15 Joining Data with pandas </summary>
    Voor mij was dit de leukste cursus van alle cursussen in Python. Zelf had ik al een grote interesse in SQL, hierbij kon ik dit combineren met Python. Ik had dit vorig jaar al geprobeerd in mijn vorige studie echter was dit toen niet gelukt. Dit jaar heb ik het daarom weer geprobeerd en lukte het wel. Een voorbeeld hiervan is te zien in de link hieronder.
      <br /> 
 https://github.com/lisadumay/ADS_Lisa_Dumaij/blob/main/notebooks/Pipeline2.ipynb
     </details>
  </details>
</details>

## 2. Reflectie en evaluatie
<details>
  <summary> Lees hier verder </summary>
  <br />
  In dit hoofdstuk reflecteer en evalueer ik terug op het afgelopen half jaar. Het hoofdstuk is opgedeeld in drie subhoofdstukken: eigen contributie, leerdoelen en de evaluatie van het project. Voor het reflecteren is de STARR methode gebruikt.
  <br />
  <br />
  <details>
  <summary>2.1 Eigen contributie</summary>
    Situatie: Voor mijn minor heb ik een project gedaan met vijf medestudenten. Ons project heet motoric en gaat over het voorspellen van motorische achterstand bij kinderen. Het project valt onder een groter project genaamd Start(V)aardig. Mijn opgestelde doelen voor dit project:<br />
-	Even grootte contributie leveren als mijn medegenoten;<br />
-	Mijn ervaringen van mijn studie meebrengen in dit project.<br />
    <br />
Taak: Halverwege van het project kreeg ik indirect de rol als projectleider deze had ik ook voor mij andere project. Door deze rol op mij te nemen kon ik zelf de taken verdelen en inplannen. Dit gaf mij de ruimte om de taken eerlijk te verdelen en zo te plannen dat de werklast voor ieder gelijk was. Mijn ervaring heb ik bij deze rol ook meegenomen. Vanuit mijn studie hebben wij geleerd dat het maken van een planning essentieel is, daarnaast moet je gebruik maken van elkaar kwaliteiten. Tot slot valt of staat het onderzoek met de inleiding en onderzoeksvraag. 
    <br /> 
    <br />
Actie: Het verdelen en plannen van taken deed ik op twee manieren. Aan het begin maakte ik een schema met welke hoofdtaken er waren en welke sub taken er vervolgens onder vielen.  Daarna verdeelde we de sub taken mondeling en plaatste ik deze op het scrumboord (planning is te zien in 3.4). Hierbij werd er gelet op dat de werklast ongeveer gelijk was. Door aan het begin een gesprek met de opdrachtgever aan te gaan kon de aanleiding van het project gedefinieerd worden. Ook gaf dit ons meer tijd om bij twijfel deze nog met de opdrachtgever te bespreken voordat wij bijvoorbeeld ‘een foute keuze’ hadden gemaakt. Daarnaast hebben wij meerdere malen gebrainstormd over de hoofdvraag, daarnaast hebben wij dit besproken met de docenten en de opdrachtgever.
    <br /> 
    <br />
Resultaten: Het heeft deels gewerkt, ik merkte dat de planning voor duidelijkheid en structuur zorgde in de groep. Ditzelfde geldt van het van tevoren opstellen van een inleiding, hierdoor wist iedereen wat er met het onderzoek bereikt moest worden en zorgde dit daarmee ook voor duidelijkheid. Wel merkte ik dat er vaak van de planning afgeweken werd, het toezicht op de planning zou daarom de volgende keer strakker mogen. De werklasten waren in dit project gelijk. 
    <br /> 
    <br />
Reflectie: Beide doelen zijn in dit project bereikt, ik ben daarom ook tevreden met de resultaten. Wel heb ik geleerd dat het houden van de planning toch meer gehandhaafd moet worden de volgende keer.  Het scrum boord zou ik in volgende projecten weer gebruiken. Ik merkte dat dit structuur en duidelijkheid gaf. Hetzelfde geldt voor de scrumsessies.

  </details>
  <details>
  <summary>2.2 Leerdoelen</summary>
Situatie: Tijdens deze minor heb ik mij zowel gefocust op mijn interpersoonlijke vaardigheden als mij (verder) ontwikkelen in mijn vaardigheden in Data science. Deze keuze heb ik gemaakt, omdat ik bij mijn vorige projecten merkte dat ik vaak mijzelf overal verantwoordelijk voor voelde waardoor ik alle taken zelf ging uitvoeren in plaats van deze verdelen. Daarbij loop ik tijdens deze studie een ander project waardoor ik ook geen tijd heb om extra taken op mij te nemen. Daarnaast heb ik hiervoor bij mijn studie nog nooit data science gehad.  Ik heb hiervoor alleen maar visualisaties gemaakt in Python. Daarom had ik de volgende doelen opgesteld:<br />
-	Geen taken overnemen van anderen;<br />
-	Meer ervaring op doen in Data Science;<br />
    <br />
Taak: Halverwege van het project kreeg ik indirect de rol als projectleider deze had ik ook voor mij andere project. Door deze rol op mij te nemen kon ik zelf de taken verdelen en inplannen. Dit gaf mij de ruimte om de taken eerlijk te verdelen en zo te plannen dat de werklast voor ieder gelijk was. De taak om meer ervaring op te doen in Data science was simpel. Nu ik eigenlijk nog geen ervaring gaven alleen al de lessen mij meer kennis over Data Science. Daarnaast zou ik deze ook kunnen toepassen in het project wat ik uitvoerde. Tot slot heb ik voor het project zelf ook literatuuronderzoek gedaan. Door deze taken verbreed ik mijn kennis over Data Science en pas ik deze direct toe.
   <br /> 
    <br />
    Actie: Het verdelen en plannen van taken deed ik op twee manieren. Aan het begin maakte ik een schema met welke hoofdtaken er waren en welke sub taken er vervolgens onder vielen. Voor de planning gebruikte ik de theorie van Brownlee (zie domein kennis hfd 5) hierdoor verbrede ik ook gelijk mijn kennis in Data Science. Daarna verdeelde we de sub taken mondeling en plaatste ik deze op het scrumboord (planning is te zien in 3.4). 
 Voor de ervaring heb ik bijna alle lessen bijgewoond (door ziekte kon ik niet altijd aanwezig zijn). Omdat de lessen voor mij soms moeilijk te begrijpen waren, heb ik na de les artikelen gezocht over dit onderwerp. Zo kon ik de theorie achter het onderwerp beter begrijpen. Vaak heb ik de codes met een teamlid geschreven. Dit deed ik omdat ik moeite had met het coderen. 
   <br /> 
    <br />
    Resultaten: De taak om geen taken over te nemen en mij minder verantwoordelijk voelen heb ik voor mijn gevoel niet gehaald. Ik heb toch vaak extra taken op mij genomen en kon het project niet loslaten. Ook als ik mij op het andere project moest focussen bleef dit project in mijn hoofd hangen. Dit heb ik uiteindelijk ook zelf gemerkt doordat mij overspannenheid erger werd en mijn concentratie afnam. Mijn doel om meer ervaring op te doen in data science heb ik volledig behaald. Door extra informatie op te zoeken begreep ik de theorie er achter veel beter. Dit hielp mij tevens naast het coderen ook bij het schrijven van het rapport. Door samen te werken met iemand kon ik leren van hun manier van coderen. Ik merkte namelijk dat mijn manier eenvoudig was maar ook langdradig in tegenstelling tot sommige teamgenoten. Hierdoor kon ik van hun leren hoe ik op een efficiëntere manier dezelfde taak kon uitvoeren.
   <br /> 
    <br />
    Reflectie: Ik heb geleerd dat ik nog meer mijn eigen grenzen moet stellen. Vaak ging ik hier toch (onbewust) overheen. Toch ben ik blij met mijn resultaten, ik heb geleerd dat het stellen van grenzen nog belangrijker is dan ik dacht. In mijn aankomende stage ga ik deze begrenzing ook meenemen. Door voor mijzelf tijden te geven om wel en niet aan het project te werken, maar ook om mijzelf de rust te geven als ik dat nodig heb. Tot slot ben ik zeer blij in wat ik heb bereikt in mijn ontwikkeling in data science. Ik vind data science zeer interessant en hoop dit ook later te kunnen toepassen in latere projecten.

  </details>
  <details>
  <summary>2.3 Evaluatie van groepsproject</summary>
   Situatie: Voor mijn minor heb ik een project gedaan met vijf medestudenten. Ons project heet motoric en gaat over het voorspellen van motorische achterstand bij kinderen. Het project valt onder een groter project genaamd Start(V)aardig. Onze doelen waren:<br />
-	Het maken van een goedwerkend voorspellingsmodel;<br />
    <br />
Taak: Onze taken waren een onderzoek artikel schrijven over onze bevindingen. Deze bevindingen bestonden uit de keuzes van outliers handling, imputatie en modelkeuze. Hiermee wilde wij de opdrachtgever toelichten waarom wij welke keuze wij hebben gemaakt. Daarnaast hebben alle opties ook zelf getest zodat het beste model uitgekozen kon worden. 
   <br /> 
    <br />
    Actie: Door de taken in teams van twee te verdelen konden we zowel parallel te werk gaan, maar hadden we ook een sparpartner als je er niet uitkwam. Twee weten immers meer dan één. Dit was ideaal gezien het aantal opties wij hadden. Daarbij hadden Joep en ik minder ervaring met Python. Door een sparpartner toe te voegen kon het werk sneller uitgevoerd worden en was de kwaliteit hoger dan als wij dit niet hadden gedaan. 
   <br /> 
    <br />
    Resultaten: De resultaten waren tegenvallend. De modellen voorspelden alleen maar 1 in plaats van dat deze gedistribueerd waren over 1 en 0. Hoewel er dus verschillende opties geprobeerd zijn heeft dit toch niet geholpen om het resultaat te verbeteren. Hierdoor is het doel om een goedwerkend model te maken niet gehaald. Gedeeltelijk is dit te verwijten aan de beschikbare data, deze was te gering. Ook waren wij te laat begonnen met het opstellen van een planning. Hierdoor wist in het begin niet iedereen waar hij/zij aan toe was en was er onduidelijk over wat er gedaan moest worden. Dit zorgde voor vertraging in het proces. Daarnaast hield niet iedereen zich aan de deadlines, waardoor er weinig tijd over was voor het finetunen van het model en het afschrijven van het onderzoek artikel.
   <br /> 
    <br />
    Reflectie: Volgende keer zou ik direct beginnen met het opstellen van een planning. Hierdoor weet iedereen welke taken er zijn en waar er naartoe wordt gewerkt. Daarbij zou het probleem van het tekort aan data eerder gezien worden en konden hier maatregelen tegen genomen kunnen worden. Toch ben ik redelijk tevreden met het resultaat. Dit omdat wij toch meerdere oplossingen geprobeerd hebben en onze best gedaan hebben. De essentie wat ik heb geleerd is ook dat soms een onverwacht resultaat ook een resultaat is. Zoals in het doel te zien is wilde ik een goedwerkend voorspellingsmodel hebben. Echter hield ik hier niet rekening mee dat een antwoord als er is geen goed voorspellend model hiervoor, ook een goed antwoord kan zijn. Dit zou ik de volgende keer wel meenemen in mijn projecten. 
  </details>
</details>

## 3.Research project
<details>
  <summary> Lees hier verder </summary>
  In dit hoofdstuk wordt het onderzoeksartikel op hoofdlijnen besproken.
  <br />
    <br />
  <details>
  <summary>3.1 Taak definitie </summary>
De hieronder opgestelde probleemstelling, doelstelling en vraagstelling is opgesteld met de van Meertens & Steenbergen (2018)
     <br />
    <br />
Probleemstelling:  <br />
Uit onderzoek van SIA is gebleken dat kinderen al op jonge leeftijd lichamelijk actief zijn, vanwege de fysieke, emotionele, sociale en persoonlijke waarde van sport en bewegen voor kinderen.  Het is daarom belangrijk om motorische achterstanden al op jonge leeftijd te ontdekken. Het is echter nog niet duidelijk welke kinderen het grootste risico lopen om een motorische achterstand te krijgen of te ontwikkelen, en welke kenmerken de grootste impact hebben op de motorische vaardigheidsontwikkeling.
     <br />
    <br />
Doelstelling: <br />
    Het op 12 januari opleveren van een voorspellingsmodel voor de motoriek van kinderen tussen 4 en 6.
     <br />
    <br />
Vraagstelling: <br />
“Hoe kan data science worden gebruikt om te voorspellen of een kind een jaar later kans heeft om een motorische achterstand te ontwikkelen?”
     <br />
    <br />
De hoofdvraag bestaat uit de volgende deelvragen:
- Welke biologische en socio-demografische variabelen hebben invloed op de motorische ontwikkeling van kinderen?
- Welk model heeft het laagste percentage fout-negatieven?
- Welke biologische en socio-demografische kenmerken hebben de grootste invloed op het model?
- Welke kenmerken hebben de kinderen met een motorische achterstand gemeen?
 <br />
    <br />
Literatuur <br />
Meertens, E., & Steenbergen, E. (2018). Onderzoek doen! https://blackboard.hhs.nl/bbcswebdav/pid-3327820-dt-content-rid-29819196_2/courses/TBK-PRH1-16-2021/TBK-PRH1-16-2020_ImportedContent_20200827125140/Onderzoek%20doen.pdf
        </details>
  <details>
  <summary>3.2 Evaluatie </summary>
 Voor het toekomstige werk raad ik aan Start(V)aardig aan om de dataset uit te breiden met gegevens vanuit CBS. Tevens raad ik aan om de dataset uit te breiden of de gaten in de dataset aan te vullen.  Dit omdat de algoritmes niet optimaal konden werken door een tekort aan data. Dit is ook terug te zien in de waardes van de false negative rate. Deze waren op een na allemaal gelijk. 
<br />
    <br />
    Ook is er momenteel sprake van overfitting. Dit is te zien aan de accurancy scores van de trainingsets. Mogelijke oplossingen ervoor zijn versimpelen model, meer training data, minder features, meer regularisatie, vroege terminatie. 
    <br />
    <br />
    Mocht de dataset aangevuld zijn kan het juiste model gekozen worden. Wel wordt er aangeraden om de MQ-score in binaire te doen. Daarnaast raad ik aan om een dashboard te bouwen met daarin de voorspellingswaarde van het kind met daarbij de features die ervoor hebben gezorgd. Een voorbeeld van dit dashboard is hieronder te zien.<br />
    <br />
<img width="158" alt="image" src="https://user-images.githubusercontent.com/91061840/148696407-2b4b7faa-2e53-4b38-8055-ff833a767a14.png">
    <br />
    <br />
Hierbij kan de gemiddelde score van het land, provincie of stad worden gevisualiseerd. Daarnaast is er ook een slide voor het individuele kind. Hierin staat welke score er wordt voorspelt en welke features bepalend zijn voor deze score.
    </details>
  <details>
 <summary>3.3 Conclusie </summary>
Uit het onderzoek is gebleken dat data science kan helpen met voorspelling doen of een kind een jaar later kans heeft om een motorische achterstand te ontwikkelen. Dit is gebeurd doormiddel van de theorie van Brown (2020) de dataset op te schonen. Hierna is de dat gescaled, gebalanceerd en is er een validatie code geschreven. <br />
    <br />
De feature selectie was ingewikkelder. Zoals in de figuur hieronder te zien is, scoren alleen de AST en MQ hoger dan vijf procent. Dat deze twee variabelen hoog scoren is niet verassend aangezien de MQ-categorie berekend wordt door deze factoren. De variabelen die onder de vijf procent scoren zijn weggelaten in het model. Normaal zou dit onder de twintig procent zijn (Buijs, 2017). Er is dus hier ruimte voor verbetering.  <br />
    <br />
    <img width="198" alt="image" src="https://user-images.githubusercontent.com/91061840/149023283-4b9de20b-aece-4879-b383-9d8ae167c739.png"> <br />
    <br />
    Dit resulteert ook gelijk in dat er geen karakteristieken overeenkomen tussen de kleuters met motorische achterstanden. Tot slot zijn de vijf gekozen modellen evalueert. Zoals hieronder te zien is.<br />
    <br />
 <img width="454" alt="image" src="https://user-images.githubusercontent.com/91061840/149023351-3a360604-e79b-4fa4-b851-6a1a2b1e7b35.png"> <br />
    <br />
Uit deze modellen is te herleiden dat de KNN het beste scoort. Zo overfit het KNN-model het minst ten opzichte van de andere modellen. Daarbij scoort het even laag op de False negative rate zoals de meeste andere modellen. <br />
    <br />
Kortom data science wordt gebruikt doormiddel van een mean imputation en een KNN. Waarbij een er feature selection plaats vindt voor elke variabel die lager scoort dan 0.05. Tot slot is er gebruikt gemaakt van een binaire classificatie ipv een multilabel.

    </details>
  <details>
 <summary>3.4 Planning </summary>
 Planning is altijd al een van mijn sterke punten geweest. Deze periode deed ik twee projecten te gelijker tijd hierdoor was planning essentieel. Naast dat ik alle meetings in een agenda heb staan heb ik ook een to do lijst per dag. Hierdoor weet ik precies wat ik elke dag moet doen. Daarbij hebben we dagelijks scrum sessie gehad met het team van ongeveer 15 minuten. Waarin we de taken verdeelde en/of de voortgang van de taken besproken. Tevens heb ik vaak de taken in de planner van team Motoric gezet en deze ook verdeeld.
[zie hier de planning] (https://tasks.office.com/DeHaagseHogeschool.onmicrosoft.com/nl-nl/Home/Planner#/plantaskboard?groupId=786800fb-0bab-470c-b770-bb6975403c41&planId=9Jb-xUUDp0Gu_F2YlVNn2ZYAAPLf)
Daarnaast heb ik ook figuren gemaakt om de stappen die in het proces gedaan moeten worden te weergeven. Een voorbeeld hiervan is hieronder te zien.
<img width="454" alt="image" src="https://user-images.githubusercontent.com/91061840/148651844-2394ba6b-108c-4ea8-aa3a-29a7ca526f05.png">
  </details>
  </details>
  </details>
## 4. Voorspellende analyse (niet af)
<details>
  <summary> Lees hier verder </summary>
  <br />
  <details>
  <summary>4.1 Selecteren van modellen</summary>
    Omdat het bij ons gaat om het voorspellen van een klas is er sprake van een classificatieprobleem. Een classificatiemodel zoekt een functie die optimaal inschat tot welke klasse een gegevenspunt behoort. Het kan een of meer verklarende variabelen bevatten (Brownlee, 2019). Hierna kunnen er een aantal punten na gegaan worden om de juiste modellen uit te kiezen.<br />
    <br />
Het eerste wat opvalt is de maat van de dataset, deze is niet klein. Hierdoor zijn algoritmen zoals KNN, Bagging, GradientBoost en Decision trees passend (ProjectPro, 2022). Deze zijn tevens ook gebruikt in de code. Hierna zijn de modellen gevalideert met cross validation om de prestaties van de modellen in kaart te brengen (Scikit-Learn, z.d.), echter beïnvloed dit niet de keuze van het model. Het evalueren van de resultaten uit de modellen daarentegen wel (kijk 4.2). <br />
    <br />
Literatuur<br />
    <br />
3.1. Cross-validation: evaluating estimator performance. (z.d.). Scikit-Learn. Geraadpleegd op 17 december 2021, van https://scikit-learn.org/stable/modules/cross_validation.html <br />
    <br />
Brownlee, J. (2019, May 22). Difference Between Classification and Regression in Machine Learning. Machine Learning Mastery. https://machinelearningmastery.com/classification-versus-regression-in-machine-learning/ <br />
    <br />
ProjectPro. (2022, January 3). 7 Types of Classification Algorithms in Machine Learning. https://www.projectpro.io/article/7-types-of-classification-algorithms-in-machine-learning/435#toc-18

  </details>
  <details>
  <summary>4.2 Een model configureren (niet)</summary>
  blabla
  </details>
  <details>
  <summary>4.3 Model trainen (niet)</summary>
  blabla
  </details>
  <details>
  <summary>4.4 Evalueren model </summary>
   De evaluatiecode voor het eindmodel heb ik samen met Yuliya geschreven. Hierbij hebben wij gebruik gemaakt van verschillende theorieën. Echter op hoofdlijnen hebben wij het wetenschappelijk achtikel van Novakovica en Veliovicb (2017) gebruikt. Zij omschrijven de confusionmatrix en ook de false negative rate die ook in ons onderzoek van groot belang zijn. De focus op de rate is besloten met de opdrachtgever. Daarentegen hebben we de Brownlee (2021) opgevolgd voor het maken van de precision recall curve, omdat het gaat over een binaire voorspelling. Daarnaast hebben we voor de code zelf ook een aantal bronnen gebruikt, deze zijn hieronder meegenomen in de literatuurlijst. 
     <br />
    <br />
De verschillende modellen zijn dus beoordeelt op de false negative rate, hoe lager hoe beter het model scoort. Maar ook wordt er gekeken naar de precision recall curve, deze omschrijft hoe goed een model is in het voorspellen van een goede waarde.
 <br />
    <br />
Notebook <br />
    <br />
Evaluatie: Samen met Yuliya geschreven. Link: https://github.com/lisadumay/ADS_Lisa_Dumaij/blob/main/notebooks/evaluation.ipynb 
 <br />
    <br />
Literatuurlijst <br />
    <br />
Bhandari, A. (2021, 23 juli). Confusion Matrix for Machine Learning. Analytics Vidhya. Geraadpleegd op 17 december 2021, van https://www.analyticsvidhya.com/blog/2020/04/confusion-matrix-machine-learning/  <br />
    <br />
Brownlee, J. (2021, January 12). How to Use ROC Curves and Precision-Recall Curves for Classification in Python. Machine Learning Mastery. Retrieved January 9, 2022, from https://machinelearningmastery.com/roc-curves-and-precision-recall-curves-for-classification-in-python/  <br />
    <br />
D. (2021, 30 januari). Example of Confusion Matrix in Python. Data to Fish. Geraadpleegd op 17 december 2021, van https://datatofish.com/confusion-matrix-python/  <br />
    <br />
Novakovica, J. D. J., Veljovicb, A., Ilic, S. S., Papic, Z., & Tomovic, M. (2017). Evaluation of Classification Models in Machine Learning. Theory and Applications of Mathematics & Computer Science. https://uav.ro/applications/se/journal/plugins/generic/pdfJsViewer/pdf.js/web/viewer.html?file=https%3A%2F%2Fuav.ro%2Fapplications%2Fse%2Fjournal%2Findex.php%2FTAMCS%2Farticle%2Fdownload%2F158%2F126%2F  <br />
    <br />
Scikit-learn: How to obtain True Positive, True Negative, False Positive and False Negative. (2015, 9 juli). Stack Overflow. Geraadpleegd op 17 december 2021, van https://stackoverflow.com/questions/31324218/scikit-learn-how-to-obtain-true-positive-true-negative-false-positive-and-fal

  </details>
  <details>
  <summary>4.5 Visualiseren (niet) </summary>
bla bla
  </details>
</details>  
  
## 5.Domein kennis (niet af)
<details>
  <summary> Lees hier verder </summary>
  <br />
  In dit hoofdstuk wordt mijn domein kennis besproken. Het hoofdstuk is opgedeeld in 3 hoofdstukken.
   <br />
   <br />
  <details>
  <summary>5.1 Introductie vakgebied </summary>
      <br />
Het vakgebied waar mijn onderzoek onder valt is de grove motorische ontwikkeling van kinderen tussen de 4 en 6 jaar. De grove motoriek bestaat uit de ontwikkelin g van bewegingen waarbij grote groepen spieren bij betrokken zijn (zoals lopen) (Laurent De Angelo e.a., 2005). Kinderen tussen de 4 en 6 jaar vallen onder de categorie ‘kleuters’.  In deze leeftijdsgroep vindt er een grote ontwikkeling in de motorische vaardigheden plaats zo leren ze rennen, klimmen maar ook gooien met een bal. De kleuters gebruiken vaak nog wel al hun spieren in plaats van één spiergroep, dit kost veel energie (Feldman, 2011).  <br />
   <br />
    
Echter komt het steeds vaker voor dat kinderen motorische achterstanden oplopen. Dit komt omdat kleuters steeds minder bewegen en er steeds meer voor hen uit handen genomen wordt door ouders of verzorgers. Tot slot zitten kinderen veel meer achter de computer dan voorheen (Sia, 2019).  <br />
   <br />
    
 Dit heeft een negatieve invloed op zowel de cognitieve als emotionele ontwikkeling van kleuters, maar ook op de participatie in het dagelijkse leven (van Luit, 2020). Doordat deze juist in de eerste levensjaren worden ontwikkeld, heeft dit ook een negatieve invloed op het functioneren op volwassen leeftijd (Berlin, Brooks- Gunn, McCarton, & McCormick, 1998; Ramey & Ramey, 1998).  Om deze reden is het zinvolle te bekijken aspecten van de motor ontwikkeling.  <br />
   <br />
Er zijn meerdere factoren die een invloed hebben op de motorische ontwikkeling volgens Laurent de Angelo e.a. (2005). Zoals biologische, sociale en omgevingsfactoren. Hoewel er wel een duidelijk verband is tussen omgevingsfactoren en intellectuele ontwikkeling is dit niet gevonden met de motorische ontwikkeling (Aboot & Bartlett, 2001).  <br />
   <br />
Om de motorische vaardigheid te bepalen wordt ‘Motor learning’ gebruikt. Dit is de studie van het verwerven van bewegingsvaardigheden en de verbetering van geleerde activiteiten door het oefenen. Het bij staat het leerproces van de individu centraal. Factoren zoals motivatie, aandacht en vermoeidheid kunnen van invloed zijn op de prestaties van het kind (Kovacs, 2008).  <br />
   <br />
Het achterhalen van waar de motorische achterstanden is in meerdere studies omschreven zo wordt er bijvoorbeld in de onderzoeken van Gilbert (1980) en de Meester e.a. (2020) gekeken naar kenmerken van de kinderen en hun achtergrond. In de onderzoeken van Wang e.a. (2020) en Zysset e.a. werden de ouderenquêtes onderzocht.  <br />
   <br />
    Literatuur <br />
   <br />
Abbott, A. L. & Bartlett, D. J. (2001). Infant motor development and equipment use in the home. Child: Care, Health and Development, 27, 295-306. doi:10.1046/j.1365-2214.2001.00186.x <br />
   <br />
Berlin, L. J., Brooks-Gunn, J., McCarton, C., & McCormick, M. C. (1998). The effectiveness of early intervention: examining risk factors and pathways to enhanced development. Preventive Medicine, 27, 238-245. doi:10.1006/pmed.1998.0282 <br />
   <br />
Feldman, R. S. (2011). Ontwikkelingspsychologie. Pearson Education Benelux B.V. <br />
   <br />
Gilbert, J. (1980). An Assessment of Motor Music Skill Development in Young Children. Journal of Research in Music Education, 28(3), 167–175. Retrieved December 17, 2021, from https://doi.org/10.2307/3345234 <br />
   <br />
Kovacs, C. R. (2008). Measuring Motor Skill Learning—A Practical Application. Strategies, 22(2), 25–29. https://doi.org/10.1080/08924562.2008.10590813 <br />
   <br />
Laurent De Angelo, M. S., Brouwers- De Jong, E. A., Bijlsma- Schlösser, J. F. M., Bulk- Bunschoten, A. M. W., Pauwels, J. H., & Steinbuch- Linstra, I. (2005). Ontwikkelingsonderzoek in de jeugdgezondheidszorg. Het van Wiechenonderzoek. De Baeche-Fassaert Motoriektest. Assen: Koninklijke Van Gorcum. <br />
   <br />
Meester, D. A. (2020, September 24). The Relationship Between Actual and Perceived Motor Competence in Children, Adolescents and Young Adults: A Systematic Review and Meta-analysis. SpringerLink. Retrieved December 8, 2021, from https://link.springer.com/article/10.1007/s40279-020-01336-2?error=cookies_not_supported&code=37b734cf-1842-49b4-a1db-a4832a112243 <br />
   <br />
Sia. (2019). Aanvraagformulier RAAK-PRO Start (V)aardig -2018. Nationaal Regieorgaan Praktijkgericht Onderzoek SIA. <br />
   <br />
Wang, H., Chen, Y., Liu, J., Sun, H., & Gao, W. (2020). A Follow-Up Study of Motor Skill Development and Its Determinants in Preschool Children from Middle-Income Family. BioMed Research International, 2020, 1–13. Retrieved December 1, 2021, from https://doi.org/10.1155/2020/6639341 <br />
   <br />
Zhang, S., Li, X., Zong, M., Zhu, X., & Wang, R. (2018). Efficient kNN Classification with Different Numbers of Nearest Neighbors. IEEE Transactions on Neural Networks and Learning Systems, 29(5), 1774–1785. Retrieved December 2, 2021, from https://doi.org/10.1109/tnnls.2017.2673241

  </details>

 <details>
  <summary>5.2 Literatuuronderzoek (niet) </summary>
   blabla

  </details>

 <details>
  <summary>5.3 Uitleg van terminologie, jargon en definities </summary>
blabla
  </details>
  
 </details>
  
</details>

## 6. Data preprocessing (niet af)
<details>
  <summary> Lees hier verder </summary>
  <br />
  <details>
  <summary>6.1 Data exploratie </summary>
    Voor de data exploratie heb ik meerdere visualisaties geprobeerd, zoals een implot, histogram, scatterplot, barplot, boxplot, distplot en een countplot. Enkele voorbeelden zijn: <br />
   <br />
De implot heb ik gebruikt om de correlatie tussen de BMI en MQ-score in kaart te brengen. Hierbij zijn de stippen gekleurd in de behorende categorie. Uit deze visualisatie is gebleken dat er bijna geen correlatie is tussen de BMI en de MQ-categorie. Daarnaast is ook de scatterplot gebruikt om de correlatie van MQ-score met de BMI te visualiseren. Hierin is te zien dat er enkele uitschieters zijn. <br />
   <br />
Het histogram is gebruikt om de distributie van de BMI te visualiseren. Hieruit is gebleken dat de meeste kinderen een BMI tussen de 15 en 20 hebben. Er zijn maar enkele uitschieters boven de 25. Een countplot heeft de distributie van MQ-categorie gevisualiseerd. Hierin is te zien dat de klas 3 minimaal twee keer zoveel voorkomt dan elke andere klas.<br />
   <br />
Tot slot heb ik ook een heatmap gemaakt, deze is hieronder tevens terug te zien. Hierbij hebben de postcoder_cijfer, zelf_lopen, naar_bed_doordeweeks en zelf_buitenspelen_vrienden een correlatie van 0.8 of hoger. Volgens de theorie van Buijs (2018) is hier sprake van een zeer sterk verband, hierdoor zijn de helft van deze features overbodig. <br />
   <br />
    <img width="256" alt="image" src="https://user-images.githubusercontent.com/91061840/148798356-61ea6d3b-31a4-47b1-9d4f-055cf31c5de1.png">

De (andere) gemaakte visualisaties zijn te vinden in de volgende notebook, beide bestanden heb ik individueel gemaakt:<br />
   <br />
Heatmap: https://github.com/lisadumay/ADS_Lisa_Dumaij/blob/main/notebooks/Pipeline%20heatmap.ipynb <br />
   <br />
Heatmap 2: https://github.com/lisadumay/ADS_Lisa_Dumaij/blob/main/notebooks/heatmaptotal.ipynb <br />
   <br />
Visualisaties: https://github.com/lisadumay/ADS_Lisa_Dumaij/blob/main/notebooks/visualisaties.ipynb <br />
   <br />

Literatuur<br />
   <br />
Buijs, A. (2017). Statistiek om mee te werken. Noordhoff. <br />
   <br />
Chart choosing. (2019, October 21). Chart.Guide. https://chart.guide/charts/chart-choosing/ <br />
   <br />
Galarnyk, M. (2020, July 6). Understanding Boxplots - Towards Data Science. Medium. https://towardsdatascience.com/understanding-boxplots-5e2df7bcbd51 <br />
   <br />
Tanner, G. (2021, December 7). Introduction to Data Visualization in Python - Towards Data Science. Medium. https://towardsdatascience.com/introduction-to-data-visualization-in-python-89a54c97fbed <br />
   <br />
The Data Visualisation Catalogue. (n.d.). The Data Visualisation Catalogue. https://datavizcatalogue.com/ <br />
   <br />

  </details>
  <details>
  <summary>6.2 Data schoonmaken </summary>
  Voor het schoonmaken van de data heb ik de theorie van Brownlee (2020) gebruikt. Deze theorie beschrijft het voorbereiden van de data voor machine learning. Machine learning gebruiken wij voor dit project vandaar de keuze. De theorie split de data cleaning op in drie: basics, outliers en missing. Hierin heb ik de volgende stappen genomen:
    <br />
    <br />
Basis <br />
    <br />
- Identificeer kolommen die een enkele waarde bevatten: als een kenmerk slechts één type variabele bevat, wordt gezegd dat het een nulvariantievoorspeller is. Dit komt omdat er geen variatie is. Het achterhalen van deze nulvariantievoorspeller kan worden gedaan door middel van de unieke functie van Numpy. Dan kunnen deze rijen worden verwijderd (Kuhn & Johnson, 2019).<br />
- Identificeer rijen die dubbele gegevens bevatten: als er rijen met dubbele waarden in de gegevens zijn, kan dit misleidend zijn voor de modelevaluatie, of ze kunnen nutteloos zijn. De dubbele rijen kunnen worden gevonden door de functie Panda's gedupliceerd (). Aangezien de gegevens zich al in de voltooide dataset bevinden, is het niet nodig om beide te bewaren. Een van de waarden kan dus worden verwijderd (Kazil & Jarmul, 2016).<br />
- Pas het formaat van de opgenomen datums aan: Als er datums zijn die verschillende formaten hebben, moeten deze worden aangepast tot één coherent formaat, zodat bijvoorbeeld gegevensvergelijking mogelijk is tussen die specifieke gegevens. Daarom moet worden ingesteld welk formaat voor datums zal worden gebruikt. Als het gekozen formaat punten moet gebruiken, moeten datums met schuine strepen of koppeltekens worden gewijzigd. Daarnaast moet de volgorde van "dd-mm-jj" worden ingesteld op één samenhangend formaat en worden aangepast in de datums die nog niet voor dat formaat gelden. Deze wijzigingen zullen er ook toe bijdragen dat de datumgegevens leesbaarder worden. <br />
- Verwijder kinderen zonder bepaalde leeftijd of geboortedatum of een lagere of hogere leeftijd dan die van belang is voor de voorspelling: Alleen kinderen in de leeftijd van 4 tot 6 jaar zijn relevant voor de voorspelling. Daarom moeten alle kinderen die lager of ouder zijn dan die leeftijd uit de dataset worden verwijderd. Ook kinderen die geen leeftijdsindicatie hebben en geen geboortedatum hebben, moeten ook worden verwijderd, omdat hun leeftijd op die manier niet bekend is en niet van belang is voor de voorspelling.<br />
- Verwijder alle strings in gegevens: gegevens van belang zijn getallen, die handig zijn om een voorspelling te maken. Daarom zijn tekst, of liever strings, minder nuttig en moeten ze over het algemeen uit de dataset worden verwijderd, vooral als de tekst slechts een opmerking is.<br />
- Verwijder basiskolommen uit de T1-gegevens die identiek zijn aan dezelfde kolommen in de T0-gegevens: Bij het samenvoegen van gegevens moet aandacht worden besteed aan kolommen die mogelijk geheel identiek zijn, waardoor het zinloos is om ze twee keer op te nemen in de uiteindelijke gegevensset. Bij het vergelijken van de T0- en T1-data valt op dat de kolommen Respondentnummer, Geslacht_x, Postcode en Geboortedatum in beide datasets identiek zijn, wat betekent dat de kolommen uit de tweede dataset kunnen worden geschrapt om die kolommen slechts één keer op te nemen in de uiteindelijke dataset.<br />
    <br />
    <br />
uitschieters<br />
    <br />
- Identificatie en verwijdering van uitbijters: een uitbijter kan worden gedefinieerd als een meet- of invoerfout, gegevenscorruptie of een echte uitbijterwaarneming. De methoden die in dit project zullen worden gebruikt:<br />
o Strings verwijderen: Voor dit onderzoek zijn alleen numerieke getallen van belang. Dus als er een string in een kolom staat, kan deze waarde worden verwijderd. In de dataset zijn alleen numerieke kolommen, maar er waren verschillende benaderingen voor het omgaan met ontbrekende gegevens. Bijvoorbeeld kinderen die hun waargenomen motorische competentie niet wilden invullen. Een benadering is om de kolommen gewoon leeg te laten en een andere is het invullen van een string zoals een "x" of "?". Deze letter of niet-numerieke waarde kan niet worden geconverteerd naar een getal, dus het moet worden verwijderd en de kolom moet leeg blijven (met een "NaN" -waarde). Anders kan de kolom niet worden geconverteerd naar een numerieke kolom en verwerkt de modelvoorspelling de waarde als een tekenreeks in plaats van een categorische numerieke waarde, zodat dit kan leiden tot voorspellingsfouten.<br />
o Methode voor gemiddelde en standaarddeviatie: deze methode voor het detecteren van uitbijters is een eenvoudige benadering en gebruikt het gemiddelde en de standaarddeviatie van een kolom. Als een waarde kleiner is dan het verschil van het gemiddelde en de standaarddeviatie of als een waarde groter is dan de som van het gemiddelde en de standaarddeviatie, dan is het een uitbijter en moet deze worden verwijderd.
Value > Mean + standard deviation  OR  value < mean – standard deviation <br />
o Interkwartielafstandsmethode: Deze methode kan worden gebruikt door de vragenlijst van de ouders en de tests omdat in beide gevallen de waarde tussen nul en vijf moet liggen. Als de een waarde is die niet tussen die getallen ligt, is dit een uitbijter.
De interkwartielafstandsmethode verdeelt de gegevens in kwartielen. Het 25e percentiel, 50e percentiel, 75e percentiel en 100e percentiel. Voor detectie van uitbijters moet de middelste 50% worden berekend en alles daaronder (onder het 25e percentiel) en alles daarboven (boven het 75e percentiel) zijn uitbijters die kunnen worden verwijderd. De middelste 50% kan worden berekend met deze formule:
IQR = Q3(75th percentile) – Q1(25th percentile) <br />
    <br />
    <br />
Missend<br />
    <br />
-	Markering: de lege cellen kunnen worden opgehaald met de functie isnull (). Een optie die kan worden geïmplementeerd, is het verwijderen van de kolom of rij. De keuze voor het verwijderen van een kolom of rij hangt af van waar de waarden ontbreken. Als er veel waarden in één kolom ontbreken, kan de kolom worden verwijderd. Als er veel variabelen in een rij ontbreken, is de keuze om deze te verwijderen en niet de kolom. Een andere manier om met de lege cellen om te gaan is door imputatie.<br />
-	Imputatie: Er zijn verschillende benaderingen voor imputatie.<br />
o KNN Imputatie: KNN staat voor de k-Nearest Neighbours methode en wordt gebruikt voor het imputeren van de data. Het is al gebouwd in Scikit-Learn en berekent het gemiddelde van de naaste buren. Hoeveel naaste buren het algoritme moet gebruiken, wordt gespecificeerd door de parameter n_neighbours (standaard = 5). Maar voor deze imputatiemethode moeten categorische of stringkenmerken worden gecodeerd. Dit kan worden gedaan door de ingebouwde functie get_dummies () van panda te gebruiken of door de ingebouwde encoder van Scikit-learns te gebruiken. Voor dit voorbeeld wordt de LabelEncoder gebruikt omdat in de dataset notities in de vorm van zinnen (strings) staan.<br />
o Imputeren met mediaan en gemiddelde: Het gebruik van mediaan en gemiddelde om gegevens toe te rekenen is een statistische benadering van gegevensimputatie. Daarvoor wordt de mediaan en het gemiddelde berekend voor een specifieke kolom die geïmputeerd moet worden. De ontbrekende waarden in die kolom worden vervolgens gevuld met het eerder berekende gemiddelde en de mediaan.<br />
<br />
    <br />
De technieken die hierboven staan heb ik ook (deels) toegepast in mijn notebooks, de notebooks zijn:
Pipeline lisa; hierin heb ik grotendeels de code zelf geschreven echter heb ik ook soms die van een ander gebruikt. Dat staat er dan ook bij. Link: <br />
    https://github.com/lisadumay/ADS_Lisa_Dumaij/blob/main/notebooks/Pipeline%20Lisa.ipynb 
    <br />
    <br />
Pipeline 2: geldt hetzelfde als Pipeline lisa. Link: https://github.com/lisadumay/ADS_Lisa_Dumaij/blob/main/notebooks/Pipeline2.ipynb 
    <br />
    <br />
Cleaning: Deze heb ik samen met Yuliya geschreven. Link: https://github.com/lisadumay/ADS_Lisa_Dumaij/blob/main/notebooks/Data%20cleaning.ipynb 
<br />
    <br />
    Outliers: Deze code heb ik zelf geschreven. https://github.com/lisadumay/ADS_Lisa_Dumaij/blob/main/notebooks/outliers.ipynb
    <br />
    <br />
Ander gebruikte theorieën voor dit onderwerp:
    <br />
    <br />
Brownlee, J. (2020a). Data Preparation of Machine Learning. Jason Brownlee.
    <br />
Data Preparation for Machine Learning | DataRobot Artificial Intelligence Wiki. (2021, 3 december). DataRobot 
<br />
AI Cloud. Geraadpleegd op 17 december 2021, van https://www.datarobot.com/wiki/data-preparation/
<br />
Kim, J. K., & Fiorillo, C. D. (2017). Theory of optimal balance predicts and explains the amplitude and decay time of synaptic inhibition. Nature Communications, 8(1). https://doi.org/10.1038/ncomms14566
<br />
Matthes, E. (2018). Crash Course programmeren in Python : projectgericht leren programmeren. Visual Steps TM.
<br />
  </details>
  <details>
  <summary>6.3 Data voorbeiding </summary>
   <br />
    Data voorbereiding bestaat uit (Machine Learning Mastery, 2021): <br />
    <br />
-	Data Cleaning: het identificeren en corrigeren van fouten of fouten in de data.<br />
-	Functieselectie: identificeren van de invoervariabelen die het meest relevant zijn voor de taak.<br />
-	Gegevenstransformaties: de schaal of verdeling van variabelen wijzigen.<br />
-	Feature Engineering: nieuwe variabelen afleiden uit beschikbare gegevens.<br />
-	Dimensionaliteitsreductie: het maken van compacte projecties van de gegevens.<br />
    <br />
In de vorige paragraaf is de data cleaning besproken (en staan de notebooks), ook feature selection is al gedeeltelijk gedaan doordat de heatmap en het de overbodige features heeft gevisualiseerd hoeven deze alleen nog verwijdert te worden. Ook het lasso model Als ik terugkijk naar mijn literatuuronderzoek denk ik haast dat ik de meeste bronnen opgezocht heb voor dit onderwerp. Dit komt omdat ik liever theorie ergens over heb voordat het wordt uitgevoerd. Van Brownlee (2020) tot Schönig (2018), hoewel ik veel bronnen heb bekeken, heb ik het niet vaak kunnen toepassen. Ik heb univariate selection, feature importance en een lasso model gemaakt. Deze notebook zal hier onderaan worden toegevoegd. <br />
    <br />
Het gegevens transformatieproces heb ik niet helemaal gedaan. Ik heb wel het schalen van de gegevenssets gedaan, echt niet het balanceren. <br />
    <br />
Feature engineering verwijst naar het proces waarbij domeinkennis wordt gebruikt om de meest relevante variabelen uit ruwe gegevens te selecteren en te transformeren bij het maken van een voorspellend model met behulp van machine learning of statistische modellering. Deze technieken heb ik zelf niet toegepast tijdens deze minor eveens als de dimensionaliteitsreductie. <br />
    <br />
    Notebooks: <br />
    <br />
Heatmap: https://github.com/lisadumay/ADS_Lisa_Dumaij/blob/main/notebooks/heatmaptotal.ipynb <br />
    <br />
Lasso: https://github.com/lisadumay/ADS_Lisa_Dumaij/blob/main/notebooks/Lasso.ipynb <br />
    <br />
Feature selectie: https://github.com/lisadumay/ADS_Lisa_Dumaij/blob/main/notebooks/Feature%20selection.ipynb <br />
    <br />
    Schaling: https://github.com/lisadumay/ADS_Lisa_Dumaij/blob/main/notebooks/Networking.ipynb <br />
    <br />
    Literatuur
Balancing dataset and normalizing features: what comes first? (2017, 5 januari). Cross Validated. Geraadpleegd op 17 december 2021, van https://stats.stackexchange.com/questions/254726/balancing-dataset-and-normalizing-features-what-comes-first <br />
    <br />
Brownlee, J. (2020, 20 augustus). How to Choose a Feature Selection Method For Machine Learning. Machine Learning Mastery. Geraadpleegd op 17 december 2021, van https://machinelearningmastery.com/feature-selection-with-real-and-categorical-data/ <br />
    <br />
Kuhn, M., & Johnson, K. (2019). Feature Engineering and Selection: A Practical Approach for Predictive Models (Chapman & Hall/CRC Data Science Series) (1st ed.). Chapman and Hall/CRC.
Kumar, V. (2014). Feature Selection: A literature Review. The Smart Computing Review, 4(3). https://doi.org/10.6029/smartcr.2014.03.007 <br />
    <br />
Li, J., Cheng, K., Wang, S., Morstatter, F., Trevino, R. P., Tang, J., & Liu, H. (2018). Feature Selection. ACM Computing Surveys, 50(6), 1–45. https://doi.org/10.1145/3136625 <br />
    <br />
Miao, J., & Niu, L. (2016). A Survey on Feature Selection. Procedia Computer Science, 91, 919–926. https://doi.org/10.1016/j.procs.2016.07.111 <br />
    <br />
Roy, B. (2021, 14 december). All about Feature Scaling - Towards Data Science. Medium. Geraadpleegd op 17 december 2021, van https://towardsdatascience.com/all-about-feature-scaling-bcc0ad75cb35 <br />
    <br />
Schönig, S., Jasinski, R., Ackermann, L., & Jablonski, S. (2018). Deep Learning Process Prediction with Discrete and Continuous Data Features. Proceedings of the 13th International Conference on Evaluation of Novel Approaches to Software Engineering. Published. https://doi.org/10.5220/0006772003140319 <br />
    <br />
Saeys, Y., Inza, I., & Larranaga, P. (2007). A review of feature selection techniques in bioinformatics. Bioinformatics, 23(19), 2507–2517. https://doi.org/10.1093/bioinformatics/btm344

  </details>
  <details>
  <summary>6.4 Data uitleg</summary>
   In dit project is er gebruik gemaakt van gestructureerde data. De data bestaan uit de gegevens die verschaft zijn door de opdrachtgever.  De gegevens van de opdrachtgever bestaan uit: de competentie, motivatie, perceptie, BMI en de ouders vragenlijst. 
    <br />
   <br />
De motivatie, perceptie en een gedeelte van de ouders vragenlijst bestaat uit gecategoriseerde data (ordinale schaal). De kinderen konden kiezen tussen vier opties om hun motivatie, en perceptie te weergeven. In de vragenlijst konden ouders vaak kiezen uit verschillende antwoorden (meerkeuze vragen). Het andere deel van de vragenlijst, de BMI valt onder een ratio schaal, er is sprake van numerieke gegevens. 
    <br />
   <br />
Tot slot bestaat de gegevens zowel uit kwalitatieve als kwantitatieve data. De dataset bestaat uit 1709 rijen (kinderen) en 36 kolommen (features).
        <br />
   <br />
    Link: https://github.com/lisadumay/ADS_Lisa_Dumaij/blob/main/data/total.csv 

  </details>
  <details>
  <summary>6.5 Data visualisatie (niet)</summary>
bla bla
  </details>
</details>

## 7.Communicatie
<details>
  <summary> Lees hier verder </summary>
 In dit hoofdstuk wordt mijn bijdragen aan de communicatie tijdens dit project besproken. Het hoofdstuk is opgedeeld in twee subhoofdstukken: presentaties en rapport 
      <br />
     <br />
<details>
  <summary>7.1 Presentaties </summary>
  Ik heb in totaal vier verschillende presentaties gedaan: twee internal en twee external. Het moeilijke aan de presentaties vond het communiceren in het Engels. Engels is niet mijn sterkste vak daarnaast als ik zenuwachtig word vergeet ik soms mijn tekst. Doordat het in het Engels was, was het ook moeilijker voor mij om mij te herpakken.  <br />
 <br />
Voor al mijn gegeven presentaties heb ik zelf de PowerPoint slides gemaakt. Hierbij had ik soms help van Yuliya of Joost. Daarnaast heb ik voor elke presentatie bullet points opzet deze zijn in het bestand terug te vinden: <br /> 
  https://github.com/lisadumay/ADS_Lisa_Dumaij/blob/main/presentaties/Bullet%20points%20presentations.docx
<br /> 
  <br /> 
De data van mijn presentaties met de daarbijhorende PowerPoints zijn: <br />
  10 oktober External: https://github.com/lisadumay/ADS_Lisa_Dumaij/blob/main/presentaties/External%20presentation%20motoric%201.pptx <br /> 
  25 oktober Internal: https://github.com/lisadumay/ADS_Lisa_Dumaij/blob/main/presentaties/Internal%20presentation%204%20(lay%20out).pptx <br />
  22 november Internal: https://github.com/lisadumay/ADS_Lisa_Dumaij/blob/main/presentaties/Internal%20presentation%207.pptx <br />
  10 december External: https://github.com/lisadumay/ADS_Lisa_Dumaij/blob/main/presentaties/External%20presentation%20motoric%203.pptx <br />
  
  </details>
<details>
  
  <summary>7.2 Paper </summary>
  Voor het rapport heb ik de volgende taken gedaan:
De layout: Samen met Yuliya heb ik de lay out gedaan. Aan het begin was deze anders, echter doordat het de layout van een onderzoekrapport was in plaats van een artikel hebben we deze later verandert. Hiervoor heb ik de bronnen (Perner, 2004) en (Wrtinig a Research article, 2015). Deze bronnen zijn aan het einde toegevoegd.<br /> 
  <br /> 
De introductie: Ik heb de introductie geschreven doormiddel van informatie die verschaft was door de opdrachtgever, maar ook door het onderzoek van SIA. Daarnaast heb ik de hoofdvraag verzonnen die ook voor het onderzoek gebruikt wordt en heb ik samen met Yuliya en Joep de deelvragen opgesteld. <br /> 
  <br /> 
Voor de matrials en methods heb ik de Data cleaning, correlation, balance and scale, feature selection, validation en evaluation geschreven. Hiervoor heb ik verscheidende theorieën gebruikt zoals het boek Brownlee (2020) voor de data cleaning, tevens heb ik deze ook gebruikt voor mijn code. Maar ook Buijs (2017) voor de correlaties en een onderzoek artikel van Novakovic (2017) voor de validatie en evaluatie.<br /> 
  <br /> 
Tot slot heb ik samen met Yuliya de resultaten geschreven, die uit de code waren voorgekomen.<br /> 
  <br /> 
Literatuur<br /> 
  <br /> 
Brownlee, J. (2020a). Data Preparation of Machine Learning. Jason Brownlee. <br /> 
  <br /> 
Buijs, A. (2017). Statistiek om mee te werken (10de editie). Noordhoff.<br /> 
  <br /> 
Novakovic, J. D. J., Veljovic, A., Ilic, S. S., Papic, Z., & Tomovic, M. (2017). Evaluation of Classification Models in Machine Learning. UAV. Retrieved December 1, 2021, from https://uav.ro/applications/se/journal/index.php/TAMCS/article/view/158/126<br /> 
  <br /> 
Perneger, T. V. (2004). Writing a research article: advice to beginners. International Journal for Quality in Health Care, 16(3), 191–192. https://doi.org/10.1093/intqhc/mzh053 <br /> 
  <br /> 
Sia. (2019). Aanvraagformulier RAAK-PRO Start (V)aardig -2018. Nationaal Regieorgaan Praktijkgericht Onderzoek SIA.<br /> 
  <br /> 
Writing a Research Article. (2015). Advances in Neonatal Care, 15(3), 159–161. https://doi.org/10.1097/anc.0000000000000203

  </details>
    </details>
  

